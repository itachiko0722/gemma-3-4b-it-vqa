{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rKOmOxizJKOz",
    "outputId": "655118e0-b905-470d-d4f5-a98f79421dd8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q transformers accelerate datasets  # 必要ライブラリをインストール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.5.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.24.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.16)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.30.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.19.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2022.12.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198,
     "referenced_widgets": [
      "dad932a9fb14468187b05d030b381d40",
      "dafa848d595948269344813ae606019f",
      "5aae52cd63ff4541ba193f2737cc1692",
      "48bda141b4ee4efb8314bd418dcf7995",
      "d0e2a9d0419d457bb2796191dae10629",
      "3dfab0ee3d3442d5b83d99bdbf548b45",
      "2797c510aa534753a00ac978e721c18a",
      "c8f87827437c4e0db0da258714a4c20d",
      "6368dac1147b411bbe50d4039d5a8954",
      "f436543f85a74d9daba22177ccebeda6",
      "ae927396182045dc93da4bc888442c8e"
     ]
    },
    "id": "O3pAGl9aJOg2",
    "outputId": "fe4d40db-565f-4f36-9dd3-133c2501b319"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b16a9ebf72a84943aa7e7ac14b976406",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "processor_config.json:   0%|          | 0.00/70.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d8ab405787d415dafa56423b921ae31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chat_template.json:   0%|          | 0.00/1.61k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f45818176804175a138d584e9e981b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37690c9ad2ec4f47ae88960350800a30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.16M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b7453a548cf41e08f52968eb8594c67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/4.69M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b1af94393d4489fb858e362ff3e9a2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/33.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f449b558005c4520b5841ba0d899553a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/35.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b36026a6ff4445e2930f62064cdf410c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/662 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a4624384d7b4927aa6b3622c88c9eab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/855 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb7e9d2c32f347a9b55617f9af74368f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/90.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0624e3a5544e4000a123b40b4f137829",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1de0a2b5a58b4b01a14bd074ec175f7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.96G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffb62d0370634df5b8c172af9bff4bed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/3.64G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e4659a161d147eab0f7127ebbded27d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "437747743fab43f1b0b8fe5a10a82891",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/215 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoProcessor, AutoModelForImageTextToText\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"google/gemma-3-4b-it\")\n",
    "model = AutoModelForImageTextToText.from_pretrained(\"google/gemma-3-4b-it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "gyHvhp-AI5ss"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from datasets import Image as dsImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "XJNVSu7qIrT0"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d4ebd1cfb6e4951999786f9cb3bcf78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/3.28k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc8212a8323a44b29a981237b3286670",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/72.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a20ec6b2326e4e0cbbcd5645b7e65ddb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/139M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "546b98c72d3c4330a8fb36f0823ec015",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff50f04327d744e79c59083853d24586",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['image_id', 'url', 'width', 'height', 'coco_id', 'flickr_id', 'qas', 'image'],\n",
       "        num_rows: 500\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['image_id', 'url', 'width', 'height', 'coco_id', 'flickr_id', 'qas', 'image'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = load_dataset(\"SakanaAI/JA-VG-VQA-500\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (9.3.0)\n",
      "Collecting pillow\n",
      "  Downloading pillow-11.1.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
      "Downloading pillow-11.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pillow\n",
      "  Attempting uninstall: pillow\n",
      "    Found existing installation: Pillow 9.3.0\n",
      "    Uninstalling Pillow-9.3.0:\n",
      "      Successfully uninstalled Pillow-9.3.0\n",
      "Successfully installed pillow-11.1.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pillow==9.1\n",
      "  Downloading Pillow-9.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.7 kB)\n",
      "Downloading Pillow-9.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pillow\n",
      "  Attempting uninstall: pillow\n",
      "    Found existing installation: Pillow 10.1.0\n",
      "    Uninstalling Pillow-10.1.0:\n",
      "      Successfully uninstalled Pillow-10.1.0\n",
      "Successfully installed pillow-9.1.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pillow==9.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Pillow\n",
      "Version: 9.1.0\n",
      "Summary: Python Imaging Library (Fork)\n",
      "Home-page: https://python-pillow.org\n",
      "Author: Alex Clark (PIL Fork Author)\n",
      "Author-email: aclark@python-pillow.org\n",
      "License: HPND\n",
      "Location: /usr/local/lib/python3.10/dist-packages\n",
      "Requires: \n",
      "Required-by: torchvision\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.3.0\n"
     ]
    }
   ],
   "source": [
    "from PIL import ExifTags\n",
    "from PIL import Image\n",
    "import PIL\n",
    "print(PIL.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: pillow 11.1.0\n",
      "Uninstalling pillow-11.1.0:\n",
      "  Successfully uninstalled pillow-11.1.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting pillow==10.0.0\n",
      "  Downloading Pillow-10.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.5 kB)\n",
      "Downloading Pillow-10.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pillow\n",
      "Successfully installed pillow-10.0.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall pillow -y\n",
    "!pip install --upgrade pillow==10.0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Image\n",
    "\n",
    "ds = load_dataset(\"SakanaAI/JA-VG-VQA-500\")  # features=... は一旦省略\n",
    "ds = ds.cast_column(\"image\", Image(decode=False))  # ここまでならおそらくエラーが出ない\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "858aab28382c400e9c416e889d4115f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import io\n",
    "import PIL\n",
    "\n",
    "def decode_pil(example):\n",
    "    byte_data = example[\"image\"][\"bytes\"]\n",
    "    if byte_data is not None:\n",
    "        try:\n",
    "            # デコードだけ行う\n",
    "            pil_img = PIL.Image.open(io.BytesIO(byte_data))\n",
    "            pil_img.load()\n",
    "            # 後で推論する場合、ここで推論するか、または example に格納して返さない\n",
    "            # example[\"pil_image\"] = pil_img\n",
    "        except Exception as e:\n",
    "            print(f\"Error at id={example.get('image_id')}: {e}\")\n",
    "    # 最終的に、datasets 側には画像カラムを保存しない\n",
    "    return {k: v for k, v in example.items() if k != \"image\"}\n",
    "\n",
    "# \"image\" カラムそのものを削除する (remove_columns=[\"image\"] も使える)\n",
    "test_ds = ds[\"test\"].map(decode_pil, remove_columns=[\"image\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: google/gemma-3-4b-it\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "576be615da2949fba14a86c4c3fd2500",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bcb68e9b0654e6f898ccfbea6d4608a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:653: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `64` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All done! Saved in gemma3_inference.jsonl\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import PIL\n",
    "\n",
    "from datasets import load_dataset, Image\n",
    "from transformers import AutoProcessor, Gemma3ForConditionalGeneration\n",
    "\n",
    "# ========== 1) データセット読み込み (decode=False) ==========\n",
    "dataset_name = \"SakanaAI/JA-VG-VQA-500\"\n",
    "ds = load_dataset(dataset_name)\n",
    "ds = ds.cast_column(\"image\", Image(decode=False))\n",
    "test_ds = ds[\"test\"]\n",
    "\n",
    "# ========== 2) モデル/プロセッサの読み込み ==========\n",
    "model_id = \"google/gemma-3-4b-it\"\n",
    "print(f\"Loading model: {model_id}\")\n",
    "\n",
    "model = Gemma3ForConditionalGeneration.from_pretrained(\n",
    "    model_id,\n",
    "    trust_remote_code=True,\n",
    "    # use_auth_token=True,  # 必要なら\n",
    "    device_map=\"auto\"\n",
    ").eval()\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\n",
    "    model_id,\n",
    "    trust_remote_code=True,\n",
    "    # use_auth_token=True\n",
    ")\n",
    "\n",
    "# ========== 3) map 用の推論関数 ==========\n",
    "\n",
    "def infer_on_example(example):\n",
    "    \"\"\"\n",
    "    1つの example:\n",
    "      - image_id\n",
    "      - url\n",
    "      - qas (リスト)\n",
    "      - image (dict: {'path': str, 'bytes': bytes})\n",
    "    に対し、\n",
    "      1) 画像のバイト列を一時ファイルに書き出し\n",
    "      2) Q&Aごとにモデル推論し\n",
    "      3) 推論結果を example[\"pred_answers\"] に格納\n",
    "    する。\n",
    "    最後に 'image' カラムは削除して返す (再エンコードエラー回避)。\n",
    "    \"\"\"\n",
    "    image_id = example[\"image_id\"]\n",
    "    url = example[\"url\"]\n",
    "    qas_list = example[\"qas\"]\n",
    "    \n",
    "    img_bytes = example[\"image\"][\"bytes\"]\n",
    "    temp_path = None\n",
    "    pred_answers = []\n",
    "\n",
    "    if img_bytes is not None and qas_list is not None:\n",
    "        # 元のバイト列をそのままファイルに書き出す → Pillow を通さない\n",
    "        temp_path = f\"temp_{image_id}.jpg\"\n",
    "        with open(temp_path, \"wb\") as f:\n",
    "            f.write(img_bytes)\n",
    "\n",
    "        # Q&A ごとに推論\n",
    "        for qa in qas_list:\n",
    "            question_text = qa[\"question\"]\n",
    "            gt_answer = qa[\"answer\"]\n",
    "            qa_id = qa[\"qa_id\"]\n",
    "\n",
    "            messages = [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": \"You are a helpful Japanese vision-language assistant.\"\n",
    "                        }\n",
    "                    ]\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"image\", \"image\": temp_path},\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": f\"質問: {question_text}\\n\\n画像ID: {image_id}\\nURL: {url}\"\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ]\n",
    "\n",
    "            inputs = processor.apply_chat_template(\n",
    "                messages,\n",
    "                add_generation_prompt=True,\n",
    "                tokenize=True,\n",
    "                return_dict=True,\n",
    "                return_tensors=\"pt\"\n",
    "            ).to(model.device)\n",
    "\n",
    "            input_len = inputs[\"input_ids\"].shape[-1]\n",
    "\n",
    "            with torch.no_grad():\n",
    "                generated = model.generate(\n",
    "                    **inputs,\n",
    "                    max_new_tokens=128,\n",
    "                    do_sample=False\n",
    "                )\n",
    "\n",
    "            gen_part = generated[0][input_len:]\n",
    "            decoded_answer = processor.decode(gen_part, skip_special_tokens=True)\n",
    "\n",
    "            pred_answers.append({\n",
    "                \"qa_id\": qa_id,\n",
    "                \"question\": question_text,\n",
    "                \"pred_answer\": decoded_answer,\n",
    "                \"gt_answer\": gt_answer\n",
    "            })\n",
    "\n",
    "        # 一時ファイル削除\n",
    "        if os.path.exists(temp_path):\n",
    "            os.remove(temp_path)\n",
    "    else:\n",
    "        # 画像バイト列がない・Q&Aがない場合 (デコード失敗等)\n",
    "        if qas_list is not None:\n",
    "            for qa in qas_list:\n",
    "                pred_answers.append({\n",
    "                    \"qa_id\": qa[\"qa_id\"],\n",
    "                    \"question\": qa[\"question\"],\n",
    "                    \"pred_answer\": None,\n",
    "                    \"gt_answer\": qa[\"answer\"]\n",
    "                })\n",
    "\n",
    "    # 推論結果を格納\n",
    "    example[\"pred_answers\"] = pred_answers\n",
    "\n",
    "    # datasets に書き戻す際、image カラムを削除 (PIL エンコード回避)\n",
    "    return {k: v for k, v in example.items() if k != \"image\"}\n",
    "\n",
    "# ========== 4) map の実行 (推論) ==========\n",
    "test_inferred = test_ds.map(\n",
    "    infer_on_example,\n",
    "    batched=False,\n",
    "    remove_columns=[\"image\"]  # ここでも明示的に削除\n",
    ")\n",
    "\n",
    "# ========== 5) 結果書き出し ==========\n",
    "output_file = \"gemma3_inference_ja_vq.jsonl\"\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    for ex in test_inferred:\n",
    "        # ex[\"pred_answers\"] には Q&A の推論結果リストが入っている\n",
    "        for pa in ex[\"pred_answers\"]:\n",
    "            item = {\n",
    "                \"image_id\": ex[\"image_id\"],\n",
    "                \"url\": ex[\"url\"],\n",
    "                \"qa_id\": pa[\"qa_id\"],\n",
    "                \"question\": pa[\"question\"],\n",
    "                \"pred_answer\": pa[\"pred_answer\"],\n",
    "                \"gt_answer\": pa[\"gt_answer\"],\n",
    "            }\n",
    "            f.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(f\"All done! Saved in {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "from datasets import load_dataset, Image,Features, Value, Sequence\n",
    "from transformers import AutoProcessor, Gemma3ForConditionalGeneration\n",
    "\n",
    "def main():\n",
    "    # === 1) データセットの読み込み ===\n",
    "\n",
    "    features = Features({\n",
    "    \"image_id\": Value(\"int64\"),\n",
    "    \"url\": Value(\"string\"),\n",
    "    \"width\": Value(\"int64\"),\n",
    "    \"height\": Value(\"int64\"),\n",
    "    \"coco_id\": Value(\"int64\"),\n",
    "    \"flickr_id\": Value(\"int64\"),\n",
    "    \"qas\": Sequence({\n",
    "        \"a_objects\": Sequence(Value(\"string\")),\n",
    "        \"answer\": Value(\"string\"),\n",
    "        \"q_objects\": Sequence(Value(\"string\")),\n",
    "        \"qa_id\": Value(\"int64\"),\n",
    "        \"question\": Value(\"string\"),\n",
    "    }),\n",
    "    # Image(decode=False) を指定\n",
    "    \"image\": Image(decode=True),\n",
    "})\n",
    "    \n",
    "    ds = load_dataset(\"SakanaAI/JA-VG-VQA-500\",features=features,ignore_verifications=True,\n",
    ")\n",
    "\n",
    "    ds = ds.cast_column(\"image\", Image(decode=True))\n",
    "    test_ds = ds[\"test\"]  # 今回は test split を利用\n",
    "\n",
    "    # === 2) モデル/プロセッサの読み込み ===\n",
    "    model_id = \"google/gemma-3-4b-it\"\n",
    "    print(f\"Loading model: {model_id}\")\n",
    "\n",
    "    model = Gemma3ForConditionalGeneration.from_pretrained(\n",
    "        model_id,\n",
    "        trust_remote_code=True,\n",
    "        use_auth_token=True,  # 必要ならトークン\n",
    "        device_map=\"auto\"\n",
    "    ).eval()\n",
    "\n",
    "    processor = AutoProcessor.from_pretrained(\n",
    "        model_id,\n",
    "        trust_remote_code=True,\n",
    "        use_auth_token=True\n",
    "    )\n",
    "\n",
    "    output_file = \"gemma3_output.jsonl\"\n",
    "\n",
    "    # === 3) 結果を書き出す準備 ===\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f_out:\n",
    "\n",
    "        # === 4) データセットの各行を順番に処理 ===\n",
    "        for i, item in enumerate(test_ds):\n",
    "            # item[\"qas\"] はリストになっており、1つの画像に対して複数の Q&A が格納されている\n",
    "            qas_list = item[\"qas\"]     # [{ \"answer\": ..., \"question\": ..., \"qa_id\": ... }, ...]\n",
    "            pil_image = item[\"image\"]  # PIL Image オブジェクト\n",
    "            image_id = item[\"image_id\"]\n",
    "            url = item[\"url\"]\n",
    "\n",
    "            # 画像を一時ファイルに保存 (テンポラリパスを作り、そこに保存する)\n",
    "            # 実行環境によっては、きちんと消すかフォルダを用意するなど調整してください。\n",
    "            temp_image_path = f\"temp_{image_id}.jpg\"\n",
    "            pil_image.save(temp_image_path)\n",
    "\n",
    "            # === 5) 各 QA 毎に推論 ===\n",
    "            for qa in qas_list:\n",
    "                question_text = qa[\"question\"]\n",
    "                gt_answer = qa[\"answer\"]  # 参考: アノテーション上の正解(実際の推論時には使わない)\n",
    "\n",
    "                # gemma3 へ与えるメッセージ (system / user)\n",
    "                messages = [\n",
    "                    {\n",
    "                        \"role\": \"system\",\n",
    "                        \"content\": [\n",
    "                            {\n",
    "                                \"type\": \"text\",\n",
    "                                \"text\": \"You are a helpful Japanese vision-language assistant.\"\n",
    "                            }\n",
    "                        ]\n",
    "                    },\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [\n",
    "                            # \"file://\" は付けずに、直接ファイルパスを指定\n",
    "                            {\"type\": \"image\", \"image\": temp_image_path},\n",
    "                            {\n",
    "                                \"type\": \"text\",\n",
    "                                \"text\": f\"質問: {question_text}\\n\\n画像ID: {image_id}\\nURL: {url}\"\n",
    "                            }\n",
    "                        ]\n",
    "                    }\n",
    "                ]\n",
    "\n",
    "                # === 6) processor を使いトークナイズ ===\n",
    "                inputs = processor.apply_chat_template(\n",
    "                    messages,\n",
    "                    add_generation_prompt=True,\n",
    "                    tokenize=True,\n",
    "                    return_dict=True,\n",
    "                    return_tensors=\"pt\"\n",
    "                ).to(model.device)\n",
    "\n",
    "                input_len = inputs[\"input_ids\"].shape[-1]\n",
    "\n",
    "                # === 7) 推論実行 ===\n",
    "                with torch.inference_mode():\n",
    "                    generated = model.generate(\n",
    "                        **inputs,\n",
    "                        max_new_tokens=128,\n",
    "                        do_sample=False\n",
    "                    )\n",
    "\n",
    "                gen_part = generated[0][input_len:]\n",
    "                decoded_answer = processor.decode(gen_part, skip_special_tokens=True)\n",
    "\n",
    "                # ログ出力\n",
    "                print(f\"[image_id={image_id} qa_id={qa['qa_id']}] Q: {question_text} => A: {decoded_answer}\")\n",
    "\n",
    "                # === 8) JSONL に書き出す ===\n",
    "                output_item = {\n",
    "                    \"image_id\": image_id,\n",
    "                    \"qa_id\": qa[\"qa_id\"],\n",
    "                    \"url\": url,\n",
    "                    \"question\": question_text,\n",
    "                    \"pred_answer\": decoded_answer,\n",
    "                    \"gt_answer\": gt_answer  # (比較用に入れる場合)\n",
    "                }\n",
    "                f_out.write(json.dumps(output_item, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "            # 処理後、念のため一時画像ファイルを削除（環境に合わせて）\n",
    "            if os.path.exists(temp_image_path):\n",
    "                os.remove(temp_image_path)\n",
    "\n",
    "    print(f\"All done! Results saved in {output_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "2797c510aa534753a00ac978e721c18a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3dfab0ee3d3442d5b83d99bdbf548b45": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "48bda141b4ee4efb8314bd418dcf7995": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f436543f85a74d9daba22177ccebeda6",
      "placeholder": "​",
      "style": "IPY_MODEL_ae927396182045dc93da4bc888442c8e",
      "value": " 1/2 [00:22&lt;00:22, 22.11s/it]"
     }
    },
    "5aae52cd63ff4541ba193f2737cc1692": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c8f87827437c4e0db0da258714a4c20d",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6368dac1147b411bbe50d4039d5a8954",
      "value": 1
     }
    },
    "6368dac1147b411bbe50d4039d5a8954": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ae927396182045dc93da4bc888442c8e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c8f87827437c4e0db0da258714a4c20d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d0e2a9d0419d457bb2796191dae10629": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dad932a9fb14468187b05d030b381d40": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_dafa848d595948269344813ae606019f",
       "IPY_MODEL_5aae52cd63ff4541ba193f2737cc1692",
       "IPY_MODEL_48bda141b4ee4efb8314bd418dcf7995"
      ],
      "layout": "IPY_MODEL_d0e2a9d0419d457bb2796191dae10629"
     }
    },
    "dafa848d595948269344813ae606019f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3dfab0ee3d3442d5b83d99bdbf548b45",
      "placeholder": "​",
      "style": "IPY_MODEL_2797c510aa534753a00ac978e721c18a",
      "value": "Loading checkpoint shards:  50%"
     }
    },
    "f436543f85a74d9daba22177ccebeda6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
